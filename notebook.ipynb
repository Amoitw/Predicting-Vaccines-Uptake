{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6086c7be",
   "metadata": {},
   "source": [
    "# Who Gets Vaccinated? Machine Learning Predictions of H1N1 and Seasonal Flu Vaccine Uptake\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f176d057",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1. Business Understanding\n",
    "The goal of this project is to develop a machine learning model that can predict the likelihood that an individual received the 2009 H1N1 vaccine and the seasonal flu vaccine based on survey responses. These predictions are to be returned as probabilities, not binary classifications. This makes the problem a multi-label probabilistic classification task — with two separate target variables to predict.\n",
    "\n",
    "By accurately predicting vaccine uptake probabilities, public health stakeholders can better understand the factors influencing vaccine behavior and potentially design targeted interventions to increase vaccination rates among underrepresented or hesitant populations.\n",
    "\n",
    "A successful model will help:\n",
    "\n",
    "1. Predict and profile vaccine-hesitant populations.\n",
    "\n",
    "2. Guide more effective public health messaging.\n",
    "\n",
    "3. Assist in real-time policy decisions during future outbreaks (e.g., COVID-19, RSV, Monkeypox).\n",
    "\n",
    "4. Serve as a foundation for equity-based healthcare interventions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9085e6a2",
   "metadata": {},
   "source": [
    "###  Stakeholders: \n",
    "The primary stakeholders for this model include:\n",
    "\n",
    "1. Public health officials and policymakers, such as those working in the CDC or WHO, who need to identify populations at higher risk of remaining unvaccinated.\n",
    "\n",
    "2. Healthcare providers and outreach programs, who can use this information to target specific groups (e.g., those with low health literacy or without insurance).\n",
    "\n",
    "3. Researchers in epidemiology and behavioral science, who seek to understand the behavioral and socio-demographic factors influencing vaccine hesitancy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0537ea1",
   "metadata": {},
   "source": [
    "### Business Goals\n",
    "Maximize prediction accuracy of vaccine uptake for both H1N1 and seasonal flu vaccines.\n",
    "\n",
    "Identify key behavioral, attitudinal, and demographic drivers of vaccine behavior.\n",
    "\n",
    "Inform public health strategy by pinpointing populations less likely to receive vaccines.\n",
    "\n",
    "Enable resource prioritization, such as focused education or mobile clinics in high-risk groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21857cdc",
   "metadata": {},
   "source": [
    "### Key Questions\n",
    "1. What individual-level characteristics (e.g., age, health status, beliefs, behavior) predict whether someone received the H1N1 or seasonal flu vaccine?\n",
    "\n",
    "2. Are there groups with disproportionately low vaccine uptake?\n",
    "\n",
    "3. How do recommendations from healthcare professionals influence vaccine behavior?\n",
    "\n",
    "4. Can this model help anticipate future vaccine hesitancy for other campaigns?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67b14d",
   "metadata": {},
   "source": [
    "# 2. Data understanding\n",
    "\n",
    "Dataset Overview\n",
    "The data originates from the National 2009 H1N1 Flu Survey, conducted in the United States to understand vaccine behaviors during the H1N1 pandemic. The full dataset includes respondent-level survey responses, capturing demographics, health status, behavioral practices, opinions about vaccines, and employment information.\n",
    "Source: 2009 National H1N1 Flu Survey (N = ~26,000)\n",
    "\n",
    "### Vaccine Dataset\n",
    "\n",
    "| File Name               | Description                                          |\n",
    "|-------------------------|------------------------------------------------------|\n",
    "| training_set_features.csv | Input features (n ≈ 26,000 respondents)            |\n",
    "| training_set_labels.csv   | Target labels for H1N1 and seasonal flu vaccine uptake |\n",
    "| test_set_features.csv     | Features for test set                              |\n",
    "\n",
    "\n",
    "\n",
    "### Target Variables\n",
    "The task is to predict two independent binary variables:\n",
    "\n",
    "Target Variable\tDescription\n",
    "|Target Variable               | Description                                          |\n",
    "|-------------------------|------------------------------------------------------|\n",
    "| H1N1_vaccine\t1 | received H1N1 vaccine           |\n",
    "| H1N1 vaccine; 0    | Did not receive |\n",
    "| Seasonal_vaccine\t1     | Received H1N1 vaccine|\n",
    "|  Seasonal flu vaccine; 0 | Did not receive |\n",
    "\n",
    "\n",
    "These are modeled separately as a multi-label problem. Some individuals received both vaccines, others only one, and many received neither."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e93e5",
   "metadata": {},
   "source": [
    "# 3. Data preparation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1aa8834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "693f7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_features = pd.read_csv('training_set_features.csv')\n",
    "train_labels = pd.read_csv(\"training_set_labels.csv\")\n",
    "test_features = pd.read_csv(\"test_set_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a9f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26707, 36)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 36 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   respondent_id                26707 non-null  int64  \n",
      " 1   h1n1_concern                 26615 non-null  float64\n",
      " 2   h1n1_knowledge               26591 non-null  float64\n",
      " 3   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 4   behavioral_avoidance         26499 non-null  float64\n",
      " 5   behavioral_face_mask         26688 non-null  float64\n",
      " 6   behavioral_wash_hands        26665 non-null  float64\n",
      " 7   behavioral_large_gatherings  26620 non-null  float64\n",
      " 8   behavioral_outside_home      26625 non-null  float64\n",
      " 9   behavioral_touch_face        26579 non-null  float64\n",
      " 10  doctor_recc_h1n1             24547 non-null  float64\n",
      " 11  doctor_recc_seasonal         24547 non-null  float64\n",
      " 12  chronic_med_condition        25736 non-null  float64\n",
      " 13  child_under_6_months         25887 non-null  float64\n",
      " 14  health_worker                25903 non-null  float64\n",
      " 15  health_insurance             14433 non-null  float64\n",
      " 16  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 17  opinion_h1n1_risk            26319 non-null  float64\n",
      " 18  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 19  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 20  opinion_seas_risk            26193 non-null  float64\n",
      " 21  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 22  age_group                    26707 non-null  object \n",
      " 23  education                    25300 non-null  object \n",
      " 24  race                         26707 non-null  object \n",
      " 25  sex                          26707 non-null  object \n",
      " 26  income_poverty               22284 non-null  object \n",
      " 27  marital_status               25299 non-null  object \n",
      " 28  rent_or_own                  24665 non-null  object \n",
      " 29  employment_status            25244 non-null  object \n",
      " 30  hhs_geo_region               26707 non-null  object \n",
      " 31  census_msa                   26707 non-null  object \n",
      " 32  household_adults             26458 non-null  float64\n",
      " 33  household_children           26458 non-null  float64\n",
      " 34  employment_industry          13377 non-null  object \n",
      " 35  employment_occupation        13237 non-null  object \n",
      "dtypes: float64(23), int64(1), object(12)\n",
      "memory usage: 7.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "employment_occupation    13470\n",
       "employment_industry      13330\n",
       "health_insurance         12274\n",
       "income_poverty            4423\n",
       "doctor_recc_h1n1          2160\n",
       "doctor_recc_seasonal      2160\n",
       "rent_or_own               2042\n",
       "employment_status         1463\n",
       "marital_status            1408\n",
       "education                 1407\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial exploration\n",
    "print(train_features.shape)\n",
    "train_features.info()\n",
    "train_features.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "605d643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 38 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   respondent_id                26707 non-null  int64  \n",
      " 1   h1n1_concern                 26615 non-null  float64\n",
      " 2   h1n1_knowledge               26591 non-null  float64\n",
      " 3   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 4   behavioral_avoidance         26499 non-null  float64\n",
      " 5   behavioral_face_mask         26688 non-null  float64\n",
      " 6   behavioral_wash_hands        26665 non-null  float64\n",
      " 7   behavioral_large_gatherings  26620 non-null  float64\n",
      " 8   behavioral_outside_home      26625 non-null  float64\n",
      " 9   behavioral_touch_face        26579 non-null  float64\n",
      " 10  doctor_recc_h1n1             24547 non-null  float64\n",
      " 11  doctor_recc_seasonal         24547 non-null  float64\n",
      " 12  chronic_med_condition        25736 non-null  float64\n",
      " 13  child_under_6_months         25887 non-null  float64\n",
      " 14  health_worker                25903 non-null  float64\n",
      " 15  health_insurance             14433 non-null  float64\n",
      " 16  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 17  opinion_h1n1_risk            26319 non-null  float64\n",
      " 18  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 19  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 20  opinion_seas_risk            26193 non-null  float64\n",
      " 21  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 22  age_group                    26707 non-null  object \n",
      " 23  education                    25300 non-null  object \n",
      " 24  race                         26707 non-null  object \n",
      " 25  sex                          26707 non-null  object \n",
      " 26  income_poverty               22284 non-null  object \n",
      " 27  marital_status               25299 non-null  object \n",
      " 28  rent_or_own                  24665 non-null  object \n",
      " 29  employment_status            25244 non-null  object \n",
      " 30  hhs_geo_region               26707 non-null  object \n",
      " 31  census_msa                   26707 non-null  object \n",
      " 32  household_adults             26458 non-null  float64\n",
      " 33  household_children           26458 non-null  float64\n",
      " 34  employment_industry          13377 non-null  object \n",
      " 35  employment_occupation        13237 non-null  object \n",
      " 36  h1n1_vaccine                 26707 non-null  int64  \n",
      " 37  seasonal_vaccine             26707 non-null  int64  \n",
      "dtypes: float64(23), int64(3), object(12)\n",
      "memory usage: 7.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "employment_occupation    13470\n",
       "employment_industry      13330\n",
       "health_insurance         12274\n",
       "income_poverty            4423\n",
       "doctor_recc_h1n1          2160\n",
       "doctor_recc_seasonal      2160\n",
       "rent_or_own               2042\n",
       "employment_status         1463\n",
       "marital_status            1408\n",
       "education                 1407\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge labels\n",
    "data = train_features.merge(train_labels, on=\"respondent_id\")\n",
    "\n",
    "# check merged data\n",
    "data.info()\n",
    "\n",
    "# Check for missing values\n",
    "data.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d251906c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>...</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26707</td>\n",
       "      <td>26707</td>\n",
       "      <td>26707</td>\n",
       "      <td>26707</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707</td>\n",
       "      <td>26707</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>lzgpxyit</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fcxhlnwr</td>\n",
       "      <td>xtkaffoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20778</td>\n",
       "      <td>15023</td>\n",
       "      <td>4297</td>\n",
       "      <td>11645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15798</td>\n",
       "      <td>15248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13353.000000</td>\n",
       "      <td>1.618486</td>\n",
       "      <td>1.262532</td>\n",
       "      <td>0.048844</td>\n",
       "      <td>0.725612</td>\n",
       "      <td>0.068982</td>\n",
       "      <td>0.825614</td>\n",
       "      <td>0.358640</td>\n",
       "      <td>0.337315</td>\n",
       "      <td>0.677264</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.886499</td>\n",
       "      <td>0.534583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.212454</td>\n",
       "      <td>0.465608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7709.791156</td>\n",
       "      <td>0.908741</td>\n",
       "      <td>0.616805</td>\n",
       "      <td>0.215258</td>\n",
       "      <td>0.444473</td>\n",
       "      <td>0.253339</td>\n",
       "      <td>0.379150</td>\n",
       "      <td>0.478828</td>\n",
       "      <td>0.472076</td>\n",
       "      <td>0.466410</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.749901</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.409052</td>\n",
       "      <td>0.498825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6676.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13353.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20029.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26706.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        respondent_id  h1n1_concern  h1n1_knowledge  \\\n",
       "count    26707.000000  26707.000000    26707.000000   \n",
       "unique            NaN           NaN             NaN   \n",
       "top               NaN           NaN             NaN   \n",
       "freq              NaN           NaN             NaN   \n",
       "mean     13353.000000      1.618486        1.262532   \n",
       "std       7709.791156      0.908741        0.616805   \n",
       "min          0.000000      0.000000        0.000000   \n",
       "25%       6676.500000      1.000000        1.000000   \n",
       "50%      13353.000000      2.000000        1.000000   \n",
       "75%      20029.500000      2.000000        2.000000   \n",
       "max      26706.000000      3.000000        2.000000   \n",
       "\n",
       "        behavioral_antiviral_meds  behavioral_avoidance  behavioral_face_mask  \\\n",
       "count                26707.000000          26707.000000          26707.000000   \n",
       "unique                        NaN                   NaN                   NaN   \n",
       "top                           NaN                   NaN                   NaN   \n",
       "freq                          NaN                   NaN                   NaN   \n",
       "mean                     0.048844              0.725612              0.068982   \n",
       "std                      0.215258              0.444473              0.253339   \n",
       "min                      0.000000              0.000000              0.000000   \n",
       "25%                      0.000000              0.000000              0.000000   \n",
       "50%                      0.000000              1.000000              0.000000   \n",
       "75%                      0.000000              1.000000              0.000000   \n",
       "max                      1.000000              1.000000              1.000000   \n",
       "\n",
       "        behavioral_wash_hands  behavioral_large_gatherings  \\\n",
       "count            26707.000000                 26707.000000   \n",
       "unique                    NaN                          NaN   \n",
       "top                       NaN                          NaN   \n",
       "freq                      NaN                          NaN   \n",
       "mean                 0.825614                     0.358640   \n",
       "std                  0.379150                     0.478828   \n",
       "min                  0.000000                     0.000000   \n",
       "25%                  1.000000                     0.000000   \n",
       "50%                  1.000000                     0.000000   \n",
       "75%                  1.000000                     1.000000   \n",
       "max                  1.000000                     1.000000   \n",
       "\n",
       "        behavioral_outside_home  behavioral_touch_face  ...  rent_or_own  \\\n",
       "count              26707.000000           26707.000000  ...        26707   \n",
       "unique                      NaN                    NaN  ...            2   \n",
       "top                         NaN                    NaN  ...          Own   \n",
       "freq                        NaN                    NaN  ...        20778   \n",
       "mean                   0.337315               0.677264  ...          NaN   \n",
       "std                    0.472076               0.466410  ...          NaN   \n",
       "min                    0.000000               0.000000  ...          NaN   \n",
       "25%                    0.000000               0.000000  ...          NaN   \n",
       "50%                    0.000000               1.000000  ...          NaN   \n",
       "75%                    1.000000               1.000000  ...          NaN   \n",
       "max                    1.000000               1.000000  ...          NaN   \n",
       "\n",
       "        employment_status  hhs_geo_region                census_msa  \\\n",
       "count               26707           26707                     26707   \n",
       "unique                  3              10                         3   \n",
       "top              Employed        lzgpxyit  MSA, Not Principle  City   \n",
       "freq                15023            4297                     11645   \n",
       "mean                  NaN             NaN                       NaN   \n",
       "std                   NaN             NaN                       NaN   \n",
       "min                   NaN             NaN                       NaN   \n",
       "25%                   NaN             NaN                       NaN   \n",
       "50%                   NaN             NaN                       NaN   \n",
       "75%                   NaN             NaN                       NaN   \n",
       "max                   NaN             NaN                       NaN   \n",
       "\n",
       "        household_adults  household_children  employment_industry  \\\n",
       "count       26707.000000        26707.000000                26707   \n",
       "unique               NaN                 NaN                   21   \n",
       "top                  NaN                 NaN             fcxhlnwr   \n",
       "freq                 NaN                 NaN                15798   \n",
       "mean            0.886499            0.534583                  NaN   \n",
       "std             0.749901            0.923836                  NaN   \n",
       "min             0.000000            0.000000                  NaN   \n",
       "25%             0.000000            0.000000                  NaN   \n",
       "50%             1.000000            0.000000                  NaN   \n",
       "75%             1.000000            1.000000                  NaN   \n",
       "max             3.000000            3.000000                  NaN   \n",
       "\n",
       "        employment_occupation  h1n1_vaccine  seasonal_vaccine  \n",
       "count                   26707  26707.000000      26707.000000  \n",
       "unique                     23           NaN               NaN  \n",
       "top                  xtkaffoo           NaN               NaN  \n",
       "freq                    15248           NaN               NaN  \n",
       "mean                      NaN      0.212454          0.465608  \n",
       "std                       NaN      0.409052          0.498825  \n",
       "min                       NaN      0.000000          0.000000  \n",
       "25%                       NaN      0.000000          0.000000  \n",
       "50%                       NaN      0.000000          0.000000  \n",
       "75%                       NaN      0.000000          1.000000  \n",
       "max                       NaN      1.000000          1.000000  \n",
       "\n",
       "[11 rows x 38 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the missing values\n",
    "def clean_missing_values(data):\n",
    "    # Fill missing values for categorical columns with mode\n",
    "    for col in data.select_dtypes(include=['object']).columns:\n",
    "        data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "    \n",
    "    # Fill missing values for numerical columns with mean\n",
    "    for col in data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        data[col].fillna(data[col].mean(), inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = clean_missing_values(data)\n",
    "\n",
    "# Check the cleaned data\n",
    "data.head()\n",
    "\n",
    "# describe the data\n",
    "data.describe(include='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afd55bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['respondent_id', 'h1n1_concern', 'h1n1_knowledge',\n",
       "       'behavioral_antiviral_meds', 'behavioral_avoidance',\n",
       "       'behavioral_face_mask', 'behavioral_wash_hands',\n",
       "       'behavioral_large_gatherings', 'behavioral_outside_home',\n",
       "       'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal',\n",
       "       'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
       "       'health_insurance', 'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
       "       'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
       "       'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'age_group',\n",
       "       'education', 'race', 'sex', 'income_poverty', 'marital_status',\n",
       "       'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa',\n",
       "       'household_adults', 'household_children', 'employment_industry',\n",
       "       'employment_occupation', 'h1n1_vaccine', 'seasonal_vaccine'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a72c6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data.drop(columns=['respondent_id', 'seasonal_vaccine', 'h1n1_vaccine'])\n",
    "y = data[['seasonal_vaccine', 'h1n1_vaccine']]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10e56471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature types\n",
    "numerical = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical = X.select_dtypes(include=[\"object\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89bb86c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat__age_group_18 - 34 Years', 'cat__age_group_35 - 44 Years',\n",
       "       'cat__age_group_45 - 54 Years', 'cat__age_group_55 - 64 Years',\n",
       "       'cat__age_group_65+ Years', 'cat__education_12 Years',\n",
       "       'cat__education_< 12 Years', 'cat__education_College Graduate',\n",
       "       'cat__education_Some College', 'cat__race_Black',\n",
       "       ...\n",
       "       'remainder__opinion_h1n1_vacc_effective',\n",
       "       'remainder__opinion_h1n1_risk',\n",
       "       'remainder__opinion_h1n1_sick_from_vacc',\n",
       "       'remainder__opinion_seas_vacc_effective',\n",
       "       'remainder__opinion_seas_risk',\n",
       "       'remainder__opinion_seas_sick_from_vacc', 'remainder__household_adults',\n",
       "       'remainder__household_children', 'remainder__h1n1_vaccine',\n",
       "       'remainder__seasonal_vaccine'],\n",
       "      dtype='object', length=108)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT CATEGORICAL VARIABLES TO NUMERICAL USING ONE-HOT ENCODING\n",
    "def convert_categorical_to_numerical(data):\n",
    "    # Identify categorical columns\n",
    "    categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Create a pipeline for categorical columns\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # Create a column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ],\n",
    "        remainder='passthrough'  # Keep the rest of the columns unchanged\n",
    "    )\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    data_transformed = preprocessor.fit_transform(data)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    data_transformed = pd.DataFrame(data_transformed, columns=preprocessor.get_feature_names_out())\n",
    "    \n",
    "    return data_transformed\n",
    "\n",
    "data_transformed = convert_categorical_to_numerical(data)\n",
    "\n",
    "\n",
    "data_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431bdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Optional: Visualize distributions\n",
    "# Example: Vaccine uptake by age group or health worker status\n",
    "\n",
    "## 3. Data Preparation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Split\n",
    "X = data.drop(columns=[\"h1n1_vaccine\", \"seasonal_vaccine\", \"respondent_id\"])\n",
    "y = data[[\"h1n1_vaccine\", \"seasonal_vaccine\"]]\n",
    "\n",
    "# Feature types\n",
    "numerical = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# Pipeline\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numerical),\n",
    "    (\"cat\", categorical_transformer, categorical)\n",
    "])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "## 4. Modeling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Pipeline for one target\n",
    "pipe_h1n1 = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_h1n1.fit(X_train, y_train[\"h1n1_vaccine\"])\n",
    "preds_h1n1 = pipe_h1n1.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_h1n1 = roc_auc_score(y_val[\"h1n1_vaccine\"], preds_h1n1)\n",
    "print(\"H1N1 ROC AUC:\", roc_auc_h1n1)\n",
    "\n",
    "# Repeat for seasonal\n",
    "pipe_seasonal = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_seasonal.fit(X_train, y_train[\"seasonal_vaccine\"])\n",
    "preds_seasonal = pipe_seasonal.predict_proba(X_val)[:, 1]\n",
    "\n",
    "roc_auc_seasonal = roc_auc_score(y_val[\"seasonal_vaccine\"], preds_seasonal)\n",
    "print(\"Seasonal ROC AUC:\", roc_auc_seasonal)\n",
    "\n",
    "## 5. Evaluation\n",
    "# Compare ROC AUCs\n",
    "mean_auc = (roc_auc_h1n1 + roc_auc_seasonal) / 2\n",
    "print(\"Mean ROC AUC:\", mean_auc)\n",
    "\n",
    "# Optional: Feature importances, SHAP, insights\n",
    "\n",
    "## 6. Deployment\n",
    "# Predict on test set\n",
    "final_preds_h1n1 = pipe_h1n1.predict_proba(test_features.drop(columns=[\"respondent_id\"]))[:, 1]\n",
    "final_preds_seasonal = pipe_seasonal.predict_proba(test_features.drop(columns=[\"respondent_id\"]))[:, 1]\n",
    "\n",
    "# Save submission\n",
    "submission = pd.DataFrame({\n",
    "    \"respondent_id\": test_features[\"respondent_id\"],\n",
    "    \"h1n1_vaccine\": final_preds_h1n1,\n",
    "    \"seasonal_vaccine\": final_preds_seasonal\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
